{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with PySpark\n",
    "\n",
    "The primary machine learning API is contained in `pyspark.ml`. It is based on PySpark DataFrames. The well-known RDD-based API `pyspark.mllib` is mainly provided for legacy purposes and might become deprecated at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from utils import download_textfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Logistic Regression') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download CSV file\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "\n",
    "download_textfile(url, save_path='../data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV file\n",
    "df = spark.read.csv('../data/titanic.csv', header=True, inferSchema=True)\n",
    "\n",
    "print(f'The data has {df.count()} rows and {len(df.columns)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show summary\n",
    "df.show(10)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "data_columns = [\n",
    "    'Survived',\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'Siblings/Spouses Aboard',\n",
    "    'Parents/Children Aboard',\n",
    "    'Fare'\n",
    "]\n",
    "\n",
    "df = df.select(data_columns) # df = df.drop('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaNs\n",
    "df = df.na.drop() # note that there are no NaNs\n",
    "\n",
    "# rename column\n",
    "df = df.withColumnRenamed('Survived', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transformations\n",
    "sex_indexer = StringIndexer(inputCol='Sex', outputCol='SexIdx')\n",
    "sex_encoder = OneHotEncoder(inputCol='SexIdx', outputCol='SexVec')\n",
    "\n",
    "feature_columns = [\n",
    "    'Pclass',\n",
    "    'SexVec',\n",
    "    'Age',\n",
    "    'Siblings/Spouses Aboard',\n",
    "    'Parents/Children Aboard',\n",
    "    'Fare'\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "lr = LogisticRegression(\n",
    "    featuresCol='features',\n",
    "    labelCol='label',\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "stages = [\n",
    "    sex_indexer, # estimator\n",
    "    sex_encoder, # estimator\n",
    "    assembler, # transformer\n",
    "    lr # estimator\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=stages) # contains transformers and estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary\n",
    "train_summary = model.stages[-1].summary\n",
    "\n",
    "train_acc = train_summary.accuracy\n",
    "train_roc_auc = train_summary.areaUnderROC\n",
    "\n",
    "train_pr = train_summary.pr.toPandas()\n",
    "train_roc = train_summary.roc.toPandas()\n",
    "\n",
    "print(f'Train acc.: {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "ax.plot(train_pr['recall'], train_pr['precision'])\n",
    "ax.set_title('Train PR curve')\n",
    "ax.set(xlabel='recall', ylabel='precision')\n",
    "ax.set(xlim=(0, 1), ylim=(0, 1))\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "ax.plot(train_roc['FPR'], train_roc['TPR'])\n",
    "ax.set_title('Train ROC curve')\n",
    "ax.set(xlabel='FPR', ylabel='TPR')\n",
    "ax.set(xlim=(0, 1), ylim=(0, 1))\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test predictions\n",
    "pred_df = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show summary\n",
    "pred_df.show(10)\n",
    "pred_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count TP, FP, TN, FN\n",
    "tp = pred_df.filter('label = 1 AND prediction = 1').count()\n",
    "fp = pred_df.filter('label = 0 AND prediction = 1').count()\n",
    "tn = pred_df.filter('label = 0 AND prediction = 0').count()\n",
    "fn = pred_df.filter('label = 1 AND prediction = 0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "test_acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "print(f'Test acc.: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble confusion matrix\n",
    "y_pred = pred_df.select('prediction').toPandas().to_numpy()\n",
    "y_true = pred_df.select('label').toPandas().to_numpy()\n",
    "\n",
    "confmat = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confmat, display_labels=(0, 1))\n",
    "disp.plot(ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate evaluators\n",
    "roc_auc_metric = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='rawPrediction',\n",
    "    labelCol='label',\n",
    "    metricName='areaUnderROC'\n",
    ")\n",
    "\n",
    "pr_auc_metric = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='rawPrediction',\n",
    "    labelCol='label',\n",
    "    metricName='areaUnderPR'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PR and ROC AUC\n",
    "pr_auc = pr_auc_metric.evaluate(pred_df)\n",
    "roc_auc = roc_auc_metric.evaluate(pred_df)\n",
    "\n",
    "print(f'Test PR AUC: {pr_auc:.4f}')\n",
    "print(f'Test ROC AUC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
